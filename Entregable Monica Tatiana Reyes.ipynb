{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eea1eff-5db2-4cc4-a17d-4bea5deb659d",
   "metadata": {},
   "source": [
    "# PCD ENTREGABLE TRANSFERENCIA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1460c-1690-48f7-b67a-5de8e0e73e05",
   "metadata": {},
   "source": [
    "# 1. Importar bibliotecas y carga de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9aeff61-7143-449d-b453-b827c9f00f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c36a512-f2f5-4519-a3bf-a8ea007c3931",
   "metadata": {},
   "source": [
    "## 1.1. Ajuste de dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c29b035b-63b3-4430-b4f2-b02a127e2767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eventos shape: (2582, 45)\n",
      "Runups shape: (26203, 30)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    IMBLEARN = True\n",
    "except Exception:\n",
    "    IMBLEARN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651664e3-3b1d-4a9a-befb-9a9d22616e6b",
   "metadata": {},
   "source": [
    "## 1.2. Creación de datasets principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347574f2-7dec-41d2-adfa-b36458f11580",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evt = pd.read_csv(\"Eventos.csv\", low_memory=False)\n",
    "df_run = pd.read_csv(\"Runups.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905a6154-9b51-458b-b6ea-7e10f510d9b1",
   "metadata": {},
   "source": [
    "# 1.3. Inspección sobre tablas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a588125-c31f-4f79-aa6f-e5e7a926205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Eventos shape:\", df_evt.shape)\n",
    "print(\"Runups shape:\", df_run.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478ed2c6-29d5-443e-87d8-37d539eb3984",
   "metadata": {},
   "source": [
    "## 1.4. Limpieza básica y creación de fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab81006-d8b2-4b93-8dfe-25a8c4f6e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_to_datetime(df):\n",
    "    # intentamos crear columna DATE si hay YEAR/MONTH/DAY\n",
    "    if {'YEAR','MONTH','DAY'}.issubset(df.columns):\n",
    "        df['DATE'] = pd.to_datetime(df[['YEAR','MONTH','DAY']], errors='coerce')\n",
    "    return df\n",
    "\n",
    "df_evt = safe_to_datetime(df_evt)\n",
    "df_run = safe_to_datetime(df_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7af16f-d973-4da4-bdd7-729d4622a3e4",
   "metadata": {},
   "source": [
    "## 1.5 Porcesamiento adicional de datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "576513ca-8526-4c7a-8aeb-df5ff666c943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes del balanceo: MAXIMUM_HEIGHT\n",
      "0    1166\n",
      "1     130\n",
      "Name: count, dtype: int64\n",
      "Después del balanceo: MAXIMUM_HEIGHT\n",
      "0    1166\n",
      "1    1166\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Variable target: ola alta (percentil 90)\n",
    "y = (df['MAXIMUM_HEIGHT'] >= df['MAXIMUM_HEIGHT'].quantile(0.90)).astype(int)\n",
    "X = df[['DISTANCE_FROM_SOURCE','TRAVEL_TIME_HOURS','PERIOD']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "print(\"Antes del balanceo:\", y_train.value_counts())\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Después del balanceo:\", pd.Series(y_res).value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8ff815-1c3b-429e-824d-275b4670cdfa",
   "metadata": {},
   "source": [
    "## 1.6. Filtrar columnas y datos relevantes - Limpiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c1e084f-7c40-4b4a-97d1-88f9576b586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_run[['DISTANCE_FROM_SOURCE','TRAVEL_TIME_HOURS','TRAVEL_TIME_MINUTES','PERIOD','MAXIMUM_HEIGHT','LATITUDE','LONGITUDE','COUNTRY','YEAR']].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c422b0a-4b68-44ab-bf41-a2be3c2facad",
   "metadata": {},
   "source": [
    "## 1.7 Limpieza de filas sin target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f52aa3-3c88-4673-bc4d-d74ce2e06d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['MAXIMUM_HEIGHT'])\n",
    "\n",
    "# Rellenar/limpiar predictoras\n",
    "df = df.replace([np.inf,-np.inf], np.nan)\n",
    "df = df.dropna(subset=['DISTANCE_FROM_SOURCE','TRAVEL_TIME_HOURS','PERIOD'], how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1401e8f8-f442-46e8-a749-66e61275cd0f",
   "metadata": {},
   "source": [
    "## 1.8. Ingenieria de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8acf577d-4ea1-4c95-8af8-30cb91df7627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# **Creación de carpeta 'outputs'**\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "# **Se guardar el archivo**\n",
    "df.to_csv(\"outputs/runups_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3da3a8a3-2d31-442a-ab06-5d1f91677823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Índice de energía aproximado**\n",
    "df['energy_idx'] = df['DISTANCE_FROM_SOURCE'] / (df['TRAVEL_TIME_HOURS']+1)\n",
    "\n",
    "# **Transformación logarítmica de la altura**\n",
    "df['log_height'] = np.log1p(df['MAXIMUM_HEIGHT'])\n",
    "\n",
    "# Guardar dataset enriquecido\n",
    "df.to_csv(\"outputs/runups_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe741831-6de4-4c2f-8dfc-7794036fe580",
   "metadata": {},
   "source": [
    "# Desarrollo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684e720c-07a9-4eea-98e2-80af0b43a395",
   "metadata": {},
   "source": [
    "## 1. Descripción estadística (guardar csv resumen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5284a111-111b-435b-a132-16cf5f312399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().to_csv(\"resumen_descriptivo_runups.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7f64f8-b711-4181-8dc9-dda7ccd59461",
   "metadata": {},
   "source": [
    "## 2.  Contraste de hipótesis (Spearman) entre magnitud (Eventos) y altura de ola (Event->Runups join)\n",
    "### uniendo tablas por SOURCE_ID / YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "026d4d93-e2b1-48b4-b171-d5f98d019a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman rho: 0.4495, p-value: 0\n"
     ]
    }
   ],
   "source": [
    "if 'SOURCE_ID' in df_evt.columns and 'SOURCE_ID' in df_run.columns:\n",
    "    merged = pd.merge(df_evt[['SOURCE_ID','PRIMARY_MAGNITUDE','DATE']],\n",
    "                      df_run[['SOURCE_ID','MAXIMUM_HEIGHT']],\n",
    "                      on='SOURCE_ID', how='inner')\n",
    "    merged = merged.dropna(subset=['PRIMARY_MAGNITUDE','MAXIMUM_HEIGHT'])\n",
    "    x = merged['PRIMARY_MAGNITUDE'].values\n",
    "    y = merged['MAXIMUM_HEIGHT'].values\n",
    "    rho, pval = stats.spearmanr(x,y)\n",
    "    print(f\"Spearman rho: {rho:.4f}, p-value: {pval:.4g}\")\n",
    "    # Guardar resultados\n",
    "    with open(\"spearman_result.txt\",\"w\") as f:\n",
    "        f.write(f\"Spearman rho: {rho}\\np-value: {pval}\\nN: {len(merged)}\\n\")\n",
    "else:\n",
    "    print(\"No hay SOURCE_ID común para hacer Spearman directo; usa los cálculos previos en PDF.\")\n",
    "    # (en tus PDFs el resultado fue rho=0.384, p~2.5e-29). :contentReference[oaicite:2]{index=2}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e585b2-1d7a-498a-83a7-3766f734c535",
   "metadata": {},
   "source": [
    "## 3. Regresión lineal (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7aaf1de-49b9-44da-ad0c-96d1284056d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression MSE: 0.3743915165839035 R2: -0.16969645769584707\n"
     ]
    }
   ],
   "source": [
    "X = df[['DISTANCE_FROM_SOURCE','TRAVEL_TIME_HOURS','PERIOD']].values\n",
    "y = df['MAXIMUM_HEIGHT'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7, random_state=42)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"LinearRegression MSE:\", mse, \"R2:\", r2)\n",
    "\n",
    "# Se Guardan coeficientes\n",
    "coef_df = pd.DataFrame({\"feature\": ['DISTANCE_FROM_SOURCE','TRAVEL_TIME_HOURS','PERIOD'],\n",
    "                       \"coef\": lr.coef_})\n",
    "coef_df.to_csv(\"linear_coefs.csv\", index=False)\n",
    "# Interpretación: si R2 negativo -> el modelo lineal no captura bien (ya reportado en tu trabajo). :contentReference[oaicite:3]{index=3} (Como digo esto con mis palabras)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8f2ec1-65ec-41fc-8829-407edb6e684c",
   "metadata": {},
   "source": [
    "### 3.1. Mejora (modelo no lineal robusto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "714e4927-9bfe-41e3-ba6f-cef6da9befe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor params RF: {'max_depth': 5, 'min_samples_leaf': 1, 'n_estimators': 200}\n",
      "RF MSE: 1.4352196998910127 R2: -3.4839995689421324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rf_regressor.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state=42)\n",
    "param_grid = {\n",
    "    \"n_estimators\":[100,200],\n",
    "    \"max_depth\":[5,10,None],\n",
    "    \"min_samples_leaf\":[1,5]\n",
    "}\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "gscv = GridSearchCV(rf, param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "gscv.fit(X_train, y_train)\n",
    "print(\"Mejor params RF:\", gscv.best_params_)\n",
    "best_rf = gscv.best_estimator_\n",
    "y_rf = best_rf.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_rf)\n",
    "r2_rf = r2_score(y_test, y_rf)\n",
    "print(\"RF MSE:\", mse_rf, \"R2:\", r2_rf)\n",
    "\n",
    "# Guardar modelo\n",
    "joblib.dump(best_rf, \"rf_regressor.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c1f352-22c7-4faa-bc2b-7530e6ad4cec",
   "metadata": {},
   "source": [
    "### 3.2. Modelos de Regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b64d6e93-65a8-49f5-a8ac-bf54504e835e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor alpha: {'alpha': 100}\n",
      "MAE medio: 0.22026358782002964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = df[['DISTANCE_FROM_SOURCE','TRAVEL_TIME_HOURS','PERIOD']]\n",
    "y = np.log1p(df['MAXIMUM_HEIGHT'])\n",
    "\n",
    "param_grid = {'alpha':[0.1, 1, 10, 100]}\n",
    "ridge = Ridge()\n",
    "\n",
    "ridge_cv = GridSearchCV(ridge, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "ridge_cv.fit(X, y)\n",
    "\n",
    "print(\"Mejor alpha:\", ridge_cv.best_params_)\n",
    "print(\"MAE medio:\", -ridge_cv.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1538811-0e4d-450d-b439-fe4ba6f55630",
   "metadata": {},
   "source": [
    "## 4. Feature importance (regresión)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a56bc307-185a-47a5-8a9d-26ca82ad299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({\n",
    "    \"feature\": ['DISTANCE_FROM_SOURCE','TRAVEL_TIME_HOURS','PERIOD'],\n",
    "    \"importance\": best_rf.feature_importances_\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "fi.to_csv(\"feature_importance_reg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2516f3-43df-4912-a81d-13cae77615df",
   "metadata": {},
   "source": [
    "## 5) Creación de variable 'high_wave' por umbral: \"percentil 90 o mediana según objetivo\"\n",
    "### En analisis anteriores se utilizo la mediana; para esta entrega utilizare un percentil 90 para concentrar \"eventos extremos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a920f47e-e19e-46e1-8e62-c8e987337a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporción de clase positiva (90th): 0.10005783689994216\n",
      "Resampled train shape: (2178, 3)\n",
      "Mejores params clasificador: {'clf__max_depth': None, 'clf__n_estimators': 200}\n",
      "Accuracy: 0.838150289017341\n",
      "Precision: 0.25\n",
      "Recall: 0.3076923076923077\n",
      "ROC AUC: 0.6518695437324988\n",
      "Confusion matrix:\n",
      " [[419  48]\n",
      " [ 36  16]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rf_classifier.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umbral_90 = df['MAXIMUM_HEIGHT'].quantile(0.90)\n",
    "df['high_wave_90'] = (df['MAXIMUM_HEIGHT'] >= umbral_90).astype(int)\n",
    "print(\"Proporción de clase positiva (90th):\", df['high_wave_90'].mean())\n",
    "\n",
    "# Features iguales\n",
    "Xc = df[['DISTANCE_FROM_SOURCE','TRAVEL_TIME_HOURS','PERIOD']]\n",
    "yc = df['high_wave_90']\n",
    "\n",
    "# dividir\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(Xc, yc, train_size=0.7, random_state=42, stratify=yc)\n",
    "\n",
    "# Opcional: SMOTE si IMBLEARN instalado (para balancear)\n",
    "if IMBLEARN:\n",
    "    sm = SMOTE(random_state=42)\n",
    "    Xc_train_res, yc_train_res = sm.fit_resample(Xc_train, yc_train)\n",
    "    print(\"Resampled train shape:\", Xc_train_res.shape)\n",
    "else:\n",
    "    Xc_train_res, yc_train_res = Xc_train, yc_train\n",
    "    print(\"SMOTE no disponible. Usando clases originales.\")\n",
    "\n",
    "# Pipeline con estandarización + RandomForestClassifier\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier(class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_clf = {\n",
    "    'clf__n_estimators':[100,200],\n",
    "    'clf__max_depth':[5,10,None],\n",
    "}\n",
    "\n",
    "gscv_clf = GridSearchCV(pipe, param_grid_clf, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "gscv_clf.fit(Xc_train_res, yc_train_res)\n",
    "print(\"Mejores params clasificador:\", gscv_clf.best_params_)\n",
    "best_clf = gscv_clf.best_estimator_\n",
    "\n",
    "# Evaluación\n",
    "yc_pred = best_clf.predict(Xc_test)\n",
    "yc_prob = best_clf.predict_proba(Xc_test)[:,1]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(yc_test, yc_pred))\n",
    "print(\"Precision:\", precision_score(yc_test, yc_pred, zero_division=0))\n",
    "print(\"Recall:\", recall_score(yc_test, yc_pred, zero_division=0))\n",
    "print(\"ROC AUC:\", roc_auc_score(yc_test, yc_prob))\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(yc_test, yc_pred)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "# Guardar modelo\n",
    "joblib.dump(best_clf, \"rf_classifier.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b77958-1ed2-41e7-8b43-cf725fb3a067",
   "metadata": {},
   "source": [
    "## 6) Comparación de experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "44284cec-5576-4e69-8c3c-92133474ea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin SMOTE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       390\n",
      "           1       0.33      0.12      0.17        43\n",
      "\n",
      "    accuracy                           0.89       433\n",
      "   macro avg       0.62      0.55      0.56       433\n",
      "weighted avg       0.85      0.89      0.86       433\n",
      "\n",
      "Con SMOTE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       390\n",
      "           1       0.22      0.26      0.24        43\n",
      "\n",
      "    accuracy                           0.84       433\n",
      "   macro avg       0.57      0.58      0.57       433\n",
      "weighted avg       0.85      0.84      0.84       433\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Sin SMOTE\n",
    "clf_no = RandomForestClassifier(random_state=42)\n",
    "clf_no.fit(X_train, y_train)\n",
    "pred_no = clf_no.predict(X_test)\n",
    "print(\"Sin SMOTE:\\n\", classification_report(y_test, pred_no))\n",
    "\n",
    "# Con SMOTE\n",
    "clf_sm = RandomForestClassifier(random_state=42)\n",
    "clf_sm.fit(X_res, y_res)\n",
    "pred_sm = clf_sm.predict(X_test)\n",
    "print(\"Con SMOTE:\\n\", classification_report(y_test, pred_sm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a511ab-6464-49c4-8115-2a8563d2760d",
   "metadata": {},
   "source": [
    "### 6.1) Estimación de incertidumbre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2ef0fa4f-b4ac-46b2-9807-590724840bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC IC 95%: 0.548 – 0.735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "model = rf_clf  # Modelo ya entrenado\n",
    "n_boot = 500\n",
    "aucs = []\n",
    "\n",
    "for i in range(n_boot):\n",
    "    Xb, yb = resample(X_test, y_test, random_state=i)\n",
    "    prob = model.predict_proba(Xb)[:,1]\n",
    "    aucs.append(roc_auc_score(yb, prob))\n",
    "\n",
    "ic_low, ic_high = np.percentile(aucs, [2.5, 97.5])\n",
    "print(f\"AUC IC 95%: {ic_low:.3f} – {ic_high:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb169f9c-9c85-46c7-876d-0fae932c2c2d",
   "metadata": {},
   "source": [
    "### 6.2 Tabla de resumen - Grafico "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "51ffca8f-2601-403d-a7c7-db63499049b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import dash_table\n",
    "\n",
    "# ==============================\n",
    "# ** Preparación datos por país\n",
    "# ==============================\n",
    "df_country = df_run['COUNTRY'].value_counts().reset_index()\n",
    "df_country.columns = ['COUNTRY', 'count']\n",
    "\n",
    "# ==============================\n",
    "# ** Exploración\n",
    "# ==============================\n",
    "tab_exploracion = dcc.Tab(label='Exploración', children=[\n",
    "    html.H4(\"Vista general de datos\"),\n",
    "\n",
    "    # Primeras filas del dataset\n",
    "    dash_table.DataTable(\n",
    "        data=df_run.head(10).to_dict('records'),\n",
    "        columns=[{\"name\": i, \"id\": i} for i in df_run.columns],\n",
    "        style_table={'overflowX': 'auto', 'maxHeight':'300px', 'overflowY':'auto'},\n",
    "        style_cell={'textAlign': 'center'}\n",
    "    ),\n",
    "\n",
    "    html.Br(),\n",
    "\n",
    "    # Scatter Magnitud vs Altura (o Distancia vs Altura)\n",
    "    dcc.Graph(id='scatter-mag-alt'),\n",
    "\n",
    "    html.P(\"Este gráfico nos mostrara la relación entre magnitud \"\n",
    "           \"y la altura de las olas.\"),\n",
    "\n",
    "    # Histograma de alturas\n",
    "    dcc.Graph(id='hist-altura'),\n",
    "\n",
    "    html.P(\"En el histograma nos mostrara la distribución de alturas de olas registradas. \"\n",
    "           \"La mayoría son bajas, lo que evidencia que los tsunamis extremos son poco frecuentes.\"),\n",
    "\n",
    "    # Gráfico por país\n",
    "    dcc.Graph(\n",
    "        figure=px.bar(\n",
    "            df_country,\n",
    "            x='COUNTRY', y='count',\n",
    "            title=\"Cantidad de registros por país\",\n",
    "            labels={'COUNTRY': 'País', 'count': 'Cantidad'}\n",
    "        )\n",
    "    ),\n",
    "\n",
    "    html.P(\"Este gráfico muestra qué países tienen más registros en la base de datos, \"\n",
    "           \"aportando contexto geográfico al análisis.\")\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a961fe85-bc72-4370-9ca4-55d36f0c1b17",
   "metadata": {},
   "source": [
    "### 6.3 gráfico de registros por país paramayor contexto geográfico a los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "de8d5e98-143e-4252-91c1-7555cffc1527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteo de registros por país\n",
    "df_country = df_run['COUNTRY'].value_counts().reset_index()\n",
    "df_country.columns = ['COUNTRY', 'count']\n",
    "\n",
    "\n",
    "# Gráfico por país dentro de la pestaña\n",
    "dcc.Graph(\n",
    "    id=\"bar-pais\",\n",
    "    figure=px.bar(\n",
    "        df_country,\n",
    "        x=\"COUNTRY\", y=\"count\",\n",
    "        title=\"Cantidad de registros por país\",\n",
    "        labels={\"COUNTRY\": \"País\", \"count\": \"Cantidad\"}\n",
    "    )\n",
    ")\n",
    "\n",
    "## Exploración completa  con las tablas de scatter, histograma y gráfico por país integrados\n",
    "tab_exploracion = dcc.Tab(label='Exploración', children=[\n",
    "    html.H4(\"Vista general de datos\"),\n",
    "\n",
    "    dash_table.DataTable(\n",
    "        data=df_run.head(10).to_dict('records'),\n",
    "        columns=[{\"name\": i, \"id\": i} for i in df_run.columns],\n",
    "        style_table={'overflowX': 'auto', 'maxHeight':'300px', 'overflowY':'auto'},\n",
    "        style_cell={'textAlign': 'center'}\n",
    "    ),\n",
    "\n",
    "    dcc.Graph(id='scatter-mag-alt'),\n",
    "    dcc.Graph(id='hist-altura'),\n",
    "\n",
    "    dcc.Graph(\n",
    "        id=\"bar-pais\",\n",
    "        figure=px.bar(\n",
    "            df_country,\n",
    "            x=\"COUNTRY\", y=\"count\",\n",
    "            title=\"Cantidad de registros por país\",\n",
    "            labels={\"COUNTRY\": \"País\", \"count\": \"Cantidad\"}\n",
    "        )\n",
    "    )\n",
    "])\n",
    "\n",
    "## \n",
    "app.layout = html.Div([\n",
    "    dcc.Tabs([\n",
    "        tab_exploracion,\n",
    "        dcc.Tab(label='Modelo - Regresión', children=[ ... ]),\n",
    "        dcc.Tab(label='Modelo - Clasificación', children=[ ... ])\n",
    "    ])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee333270-e2b3-406c-82e9-700a3b67bb42",
   "metadata": {},
   "source": [
    "## 7) Se Guardardan métricas en CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5afa9690-ab27-4ec6-8eca-e63a8805e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics = {\n",
    "    \"model\":[\"LinearReg\",\"RandomForestReg\"], \"mse\":[mse, mse_rf], \"r2\":[r2, r2_rf]\n",
    "}\n",
    "pd.DataFrame(metrics).to_csv(\"regression_metrics.csv\", index=False)\n",
    "\n",
    "clf_metrics = {\n",
    "    \"metric\":[\"accuracy\",\"precision\",\"recall\",\"roc_auc\"],\n",
    "    \"value\":[accuracy_score(yc_test, yc_pred),\n",
    "             precision_score(yc_test, yc_pred, zero_division=0),\n",
    "             recall_score(yc_test, yc_pred, zero_division=0),\n",
    "             roc_auc_score(yc_test, yc_prob)]\n",
    "}\n",
    "pd.DataFrame(clf_metrics).to_csv(\"classification_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a92cd1-abee-4267-bcda-9e08cae44949",
   "metadata": {},
   "source": [
    "### 7.1. Se Exporta archivo en CSV con features+predicciones para explorar en dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd167fe0-a3fe-4809-a698-2909704dd1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis finalizado. Archivos generados: (resumen_descriptivo_runups.csv, spearman_result.txt (si aplica), linear_coefs.csv, rf_regressor.pkl, feature_importance_reg.csv, regression_metrics.csv, rf_classifier.pkl, classification_metrics.csv, predicciones_test_clasificacion.csv\n"
     ]
    }
   ],
   "source": [
    "out = Xc_test.copy()\n",
    "out['true_high90'] = yc_test.values\n",
    "out['prob_high90'] = yc_prob\n",
    "out['pred_high90'] = yc_pred\n",
    "out.to_csv(\"predicciones_test_clasificacion.csv\", index=False)\n",
    "\n",
    "print(\"Análisis finalizado. Archivos generados: (resumen_descriptivo_runups.csv, spearman_result.txt (si aplica), linear_coefs.csv, rf_regressor.pkl, feature_importance_reg.csv, regression_metrics.csv, rf_classifier.pkl, classification_metrics.csv, predicciones_test_clasificacion.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdee64b-f8bd-40f9-afe5-ce5777eb61cf",
   "metadata": {},
   "source": [
    "## 8 Creación Dashboard interactivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f46e75-eb86-4411-9502-66687f9e2689",
   "metadata": {},
   "source": [
    "## Intalación paquete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "248eb132-3d72-43e2-ae4a-30089e1d92c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dash\n",
      "  Downloading dash-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: plotly in c:\\users\\usuario\\anaconda3\\lib\\site-packages (5.24.1)\n",
      "Requirement already satisfied: Flask<3.2,>=1.0.4 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from dash) (3.1.0)\n",
      "Requirement already satisfied: Werkzeug<3.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from dash) (3.1.3)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from dash) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from dash) (4.12.2)\n",
      "Requirement already satisfied: requests in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from dash) (2.32.3)\n",
      "Collecting retrying (from dash)\n",
      "  Downloading retrying-1.4.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from dash) (1.6.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from dash) (72.1.0)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from Flask<3.2,>=1.0.4->dash) (3.1.6)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from Flask<3.2,>=1.0.4->dash) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from Flask<3.2,>=1.0.4->dash) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from Flask<3.2,>=1.0.4->dash) (1.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from Werkzeug<3.2->dash) (3.0.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from plotly) (9.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from plotly) (24.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from click>=8.1.3->Flask<3.2,>=1.0.4->dash) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from importlib-metadata->dash) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests->dash) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests->dash) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests->dash) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests->dash) (2025.4.26)\n",
      "Downloading dash-3.2.0-py3-none-any.whl (7.9 MB)\n",
      "   ---------------------------------------- 0.0/7.9 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 7.3/7.9 MB 41.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.9/7.9 MB 33.8 MB/s eta 0:00:00\n",
      "Downloading retrying-1.4.2-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: retrying, dash\n",
      "\n",
      "   -------------------- ------------------- 1/2 [dash]\n",
      "   -------------------- ------------------- 1/2 [dash]\n",
      "   -------------------- ------------------- 1/2 [dash]\n",
      "   -------------------- ------------------- 1/2 [dash]\n",
      "   -------------------- ------------------- 1/2 [dash]\n",
      "   -------------------- ------------------- 1/2 [dash]\n",
      "   -------------------- ------------------- 1/2 [dash]\n",
      "   -------------------- ------------------- 1/2 [dash]\n",
      "   -------------------- ------------------- 1/2 [dash]\n",
      "   -------------------- ------------------- 1/2 [dash]\n",
      "   -------------------- ------------------- 1/2 [dash]\n",
      "   -------------------- ------------------- 1/2 [dash]\n",
      "   -------------------- ------------------- 1/2 [dash]\n",
      "   -------------------- ------------------- 1/2 [dash]\n",
      "   ---------------------------------------- 2/2 [dash]\n",
      "\n",
      "Successfully installed dash-3.2.0 retrying-1.4.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install dash plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58e00db2-e7a9-4a96-9933-a1b1247ad6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc, html, Input, Output\n",
    "import plotly.express as px\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a99f211-d360-4baa-9dd5-5d884cca52b0",
   "metadata": {},
   "source": [
    "### 8.1 Cargar datos Runups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2909dedd-40de-4dc8-8733-6f7a27e4d54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Runups.csv\", low_memory=False)\n",
    "df = df.dropna(subset=['MAXIMUM_HEIGHT','DISTANCE_FROM_SOURCE','TRAVEL_TIME_HOURS','PERIOD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d572c541-167a-4f85-83f5-cd72499ece11",
   "metadata": {},
   "source": [
    "### 8.2 Carga de datos y modelos (generados por analisis_modelado.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "909694eb-327e-4b31-8ab0-bb28c8316702",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Runups.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08e657c-11cb-45c9-81ff-cf90990ab420",
   "metadata": {},
   "source": [
    "### 8.3 Preprocesamiento consistente con el script analisis_modelado.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d15dadb2-53d6-4943-94f3-d9a48e39ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['MAXIMUM_HEIGHT','DISTANCE_FROM_SOURCE','TRAVEL_TIME_HOURS','PERIOD'])\n",
    "pred_df = pd.read_csv(\"predicciones_test_clasificacion.csv\") if os.path.exists(\"predicciones_test_clasificacion.csv\") else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10adc51-18d1-483f-a1e8-85b010762df9",
   "metadata": {},
   "source": [
    "### 8.4 Carga de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "13fedd53-77a5-4908-9e18-0c2584d5cf69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1e62f780c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# app.py (Dashboard con rango de años y selección múltiple de países)\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# --------------------------\n",
    "# Cargar datos y modelos\n",
    "# --------------------------\n",
    "df = pd.read_csv(\"Runups.csv\", low_memory=False)\n",
    "df = df.dropna(subset=['MAXIMUM_HEIGHT','DISTANCE_FROM_SOURCE','TRAVEL_TIME_HOURS','PERIOD'])\n",
    "\n",
    "rf_reg_path = \"rf_regressor.pkl\"\n",
    "rf_clf_path = \"rf_classifier.pkl\"\n",
    "\n",
    "rf_reg = joblib.load(rf_reg_path) if os.path.exists(rf_reg_path) else None\n",
    "rf_clf = joblib.load(rf_clf_path) if os.path.exists(rf_clf_path) else None\n",
    "\n",
    "# --------------------------\n",
    "# App\n",
    "# --------------------------\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "server = app.server\n",
    "\n",
    "# --------------------------\n",
    "# Layout\n",
    "# --------------------------\n",
    "app.layout = html.Div(\n",
    "    style={'backgroundColor': '#f9f9f9', 'padding': '20px'},\n",
    "    children=[\n",
    "        html.H1(\"Dashboard: Análisis de Tsunamis - Altura de Olas\",\n",
    "                style={'textAlign': 'center', 'color': '#003366'}),\n",
    "        html.H3(\"Exploración, Regresión y Clasificación de Olas\",\n",
    "                style={'textAlign': 'center', 'color': '#006699'}),\n",
    "\n",
    "        # filtros: rango de años y percentil\n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                html.Label(\"Filtrar por rango de años\", style={'fontWeight': 'bold'}),\n",
    "                dcc.RangeSlider(\n",
    "                    id=\"year-slider\",\n",
    "                    min=int(df['YEAR'].min()), \n",
    "                    max=int(df['YEAR'].max()),\n",
    "                    value=[int(df['YEAR'].min()), int(df['YEAR'].max())],\n",
    "                    marks={y: str(y) for y in range(int(df['YEAR'].min()), int(df['YEAR'].max())+1, 5)},\n",
    "                    step=1\n",
    "                )\n",
    "            ], style={'width': '48%', 'display': 'inline-block', 'padding': '10px'}),\n",
    "\n",
    "            html.Div([\n",
    "                html.Label(\"Selecciona umbral para 'ola alta' (percentil)\", style={'fontWeight': 'bold'}),\n",
    "                dcc.Slider(\n",
    "                    id='percentil-umbral', min=50, max=99, step=1, value=90,\n",
    "                    marks={50: '50', 75: '75', 90: '90', 95: '95', 99: '99'}\n",
    "                )\n",
    "            ], style={'width': '48%', 'display': 'inline-block', 'float': 'right', 'padding': '10px'}),\n",
    "        ], style={'marginBottom': '20px'}),\n",
    "\n",
    "        # filtro por países (multi)\n",
    "        html.Div([\n",
    "            html.Label(\"Filtrar por país\", style={'fontWeight': 'bold'}),\n",
    "            dcc.Dropdown(\n",
    "                id=\"country-dropdown\",\n",
    "                options=[{\"label\": c, \"value\": c} for c in sorted(df['COUNTRY'].dropna().unique())],\n",
    "                value=[],\n",
    "                multi=True,\n",
    "                placeholder=\"Selecciona uno o más países\"\n",
    "            ),\n",
    "            html.Button(\"Reset filtros\", id=\"reset-btn\", n_clicks=0, style={'marginTop': '6px'})\n",
    "        ], style={'marginBottom': '20px'}),\n",
    "\n",
    "        # tabs con gráficas\n",
    "        dcc.Tabs([\n",
    "            dcc.Tab(label='Exploración', children=[\n",
    "                dcc.Graph(id='scatter-mag-alt', style={'backgroundColor': 'white', 'padding': '10px'}),\n",
    "                dcc.Graph(id='hist-altura', style={'backgroundColor': 'white', 'padding': '10px'})\n",
    "            ]),\n",
    "\n",
    "            dcc.Tab(label='Modelo - Regresión', children=[\n",
    "                html.Div(id='reg-metrics', style={'marginTop': '20px'}),\n",
    "                dcc.Graph(id='pred-vs-true', style={'backgroundColor': 'white', 'padding': '10px'})\n",
    "            ]),\n",
    "\n",
    "            dcc.Tab(label='Modelo - Clasificación', children=[\n",
    "                html.Div(id='clf-metrics', style={'marginTop': '20px'}),\n",
    "                dcc.Graph(id='roc-curve'),\n",
    "                html.P(\"La curva ROC muestra el desempeño del modelo. Un AUC cercano a 0.65 \"\n",
    "                       \"indica que el modelo tiene un poder predictivo moderado.\"),\n",
    "                dcc.Graph(id='conf-matrix'),\n",
    "                html.P(\"La matriz de confusión evidencia que el modelo detecta mejor olas bajas (clase 0) \"\n",
    "                       \"que olas altas (clase 1). Esto ocurre porque los eventos extremos son poco frecuentes.\")\n",
    "            ])\n",
    "        ])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Callbacks\n",
    "# --------------------------\n",
    "\n",
    "# Reset países\n",
    "@app.callback(\n",
    "    Output(\"country-dropdown\", \"value\"),\n",
    "    Input(\"reset-btn\", \"n_clicks\")\n",
    ")\n",
    "def reset_country(n_clicks):\n",
    "    if n_clicks and n_clicks > 0:\n",
    "        return []\n",
    "    return dash.no_update\n",
    "\n",
    "# Scatter: rango de años + multi país\n",
    "@app.callback(\n",
    "    Output('scatter-mag-alt', 'figure'),\n",
    "    Input('year-slider', 'value'),\n",
    "    Input('country-dropdown', 'value')\n",
    ")\n",
    "def update_scatter(year_range, countries):\n",
    "    y0, y1 = year_range\n",
    "    dff = df[(df['YEAR'] >= y0) & (df['YEAR'] <= y1)]\n",
    "\n",
    "    if countries and len(countries) > 0:\n",
    "        dff = dff[dff['COUNTRY'].isin(countries)]\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(\"Eventos.csv\"):\n",
    "            evt = pd.read_csv(\"Eventos.csv\", low_memory=False)\n",
    "            if 'SOURCE_ID' in evt.columns and 'SOURCE_ID' in dff.columns:\n",
    "                merged = pd.merge(evt[['SOURCE_ID','PRIMARY_MAGNITUDE']], dff, on='SOURCE_ID', how='inner')\n",
    "                fig = px.scatter(merged, x='PRIMARY_MAGNITUDE', y='MAXIMUM_HEIGHT',\n",
    "                                 hover_data=['COUNTRY','YEAR'], color='PRIMARY_MAGNITUDE',\n",
    "                                 title=f\"Magnitud vs Altura ({y0}-{y1})\")\n",
    "            else:\n",
    "                fig = px.scatter(dff, x='DISTANCE_FROM_SOURCE', y='MAXIMUM_HEIGHT',\n",
    "                                 hover_data=['COUNTRY','YEAR'], color='DISTANCE_FROM_SOURCE',\n",
    "                                 title=f\"Distancia vs Altura ({y0}-{y1})\")\n",
    "        else:\n",
    "            fig = px.scatter(dff, x='DISTANCE_FROM_SOURCE', y='MAXIMUM_HEIGHT',\n",
    "                             hover_data=['COUNTRY','YEAR'], color='DISTANCE_FROM_SOURCE',\n",
    "                             title=f\"Distancia vs Altura ({y0}-{y1})\")\n",
    "    except Exception as e:\n",
    "        fig = px.scatter(pd.DataFrame({'x':[0],'y':[0]}), x='x', y='y',\n",
    "                         title=f\"No hay datos (error: {str(e)})\")\n",
    "\n",
    "    fig.update_layout(plot_bgcolor='#f0f0f0')\n",
    "    return fig\n",
    "\n",
    "# Histograma: rango + multi país\n",
    "@app.callback(\n",
    "    Output('hist-altura','figure'),\n",
    "    Input('year-slider','value'),\n",
    "    Input('country-dropdown','value')\n",
    ")\n",
    "def update_hist(year_range, countries):\n",
    "    y0, y1 = year_range\n",
    "    dff = df[(df['YEAR'] >= y0) & (df['YEAR'] <= y1)]\n",
    "\n",
    "    if countries and len(countries) > 0:\n",
    "        dff = dff[dff['COUNTRY'].isin(countries)]\n",
    "\n",
    "    fig = px.histogram(dff, x='MAXIMUM_HEIGHT', nbins=100,\n",
    "                       title=f\"Histograma de alturas ({y0}-{y1})\",\n",
    "                       color_discrete_sequence=['#003366'])\n",
    "    fig.update_layout(plot_bgcolor='#f0f0f0')\n",
    "    return fig\n",
    "\n",
    "# Métricas de regresión\n",
    "@app.callback(\n",
    "    Output('reg-metrics','children'),\n",
    "    Input('year-slider','value')\n",
    ")\n",
    "def show_reg_metrics(year_range):\n",
    "    if os.path.exists(\"regression_metrics.csv\"):\n",
    "        rm = pd.read_csv(\"regression_metrics.csv\")\n",
    "        table = html.Table(\n",
    "            [html.Tr([html.Th(c) for c in rm.columns], style={'backgroundColor':'#003366','color':'white'})] +\n",
    "            [html.Tr([html.Td(rm.iloc[i][c]) for c in rm.columns]) for i in range(len(rm))],\n",
    "            style={'border':'1px solid black', 'marginTop':'10px'}\n",
    "        )\n",
    "        return html.Div([html.H4(\"Métricas de regresión (archivo)\", style={'color':'#003366'}), table])\n",
    "    return \"No hay métricas de regresión generadas. Se corre analisis_modelado.py primero.\"\n",
    "\n",
    "# Predicciones vs verdadero\n",
    "@app.callback(\n",
    "    Output('pred-vs-true','figure'),\n",
    "    Input('year-slider','value')\n",
    ")\n",
    "def pred_vs_true(year_range):\n",
    "    if os.path.exists(\"predicciones_test_clasificacion.csv\") and rf_reg is not None:\n",
    "        dff = pd.read_csv(\"predicciones_test_clasificacion.csv\")\n",
    "        fig = px.scatter(dff, x='prob_high90', y='true_high90', hover_data=['pred_high90'],\n",
    "                         color='prob_high90', color_continuous_scale='Blues',\n",
    "                         title=\"Probabilidad predicha vs verdadero (clasificación)\")\n",
    "        fig.update_layout(plot_bgcolor='#f0f0f0')\n",
    "        return fig\n",
    "    return px.scatter(pd.DataFrame({'x':[0],'y':[0]}), x='x', y='y', title=\"Ejecución analisis_modelado.py para generar predicciones\")\n",
    "\n",
    "# Métricas de clasificación\n",
    "@app.callback(\n",
    "    Output('clf-metrics','children'),\n",
    "    Input('percentil-umbral','value')\n",
    ")\n",
    "def update_clf_metrics(percentil):\n",
    "    if os.path.exists(\"classification_metrics.csv\"):\n",
    "        cm = pd.read_csv(\"classification_metrics.csv\")\n",
    "        table = html.Table(\n",
    "            [html.Tr([html.Th(c) for c in cm.columns], style={'backgroundColor':'#006699','color':'white'})] +\n",
    "            [html.Tr([html.Td(cm.iloc[i][c]) for c in cm.columns]) for i in range(len(cm))],\n",
    "            style={'border':'1px solid black', 'marginTop':'10px'}\n",
    "        )\n",
    "        return html.Div([html.H4(f\"Métricas de clasificación (umbral {percentil} percentil)\", style={'color':'#006699'}), table])\n",
    "    return \"Se corre analisis_modelado.py primero para generar métricas de clasificación.\"\n",
    "\n",
    "# ROC y matriz de confusión\n",
    "@app.callback(\n",
    "    Output('roc-curve','figure'),\n",
    "    Output('conf-matrix','figure'),\n",
    "    Input('percentil-umbral','value')\n",
    ")\n",
    "def update_roc_cm(percentil):\n",
    "    if os.path.exists(\"predicciones_test_clasificacion.csv\"):\n",
    "        dff = pd.read_csv(\"predicciones_test_clasificacion.csv\")\n",
    "        try:\n",
    "            fpr, tpr, thr = roc_curve(dff['true_high90'], dff['prob_high90'])\n",
    "            roc_fig = px.area(x=fpr, y=tpr,\n",
    "                              title=f\"ROC curve (AUC={roc_auc_score(dff['true_high90'], dff['prob_high90']):.3f})\",\n",
    "                              color_discrete_sequence=['#006699'])\n",
    "            roc_fig.update_xaxes(title=\"False Positive Rate\")\n",
    "            roc_fig.update_yaxes(title=\"True Positive Rate\")\n",
    "        except Exception:\n",
    "            roc_fig = px.scatter(title=\"No se pudo calcular ROC\")\n",
    "\n",
    "        thresh = np.percentile(dff['prob_high90'], percentil)\n",
    "        preds = (dff['prob_high90'] >= thresh).astype(int)\n",
    "        cm = confusion_matrix(dff['true_high90'], preds)\n",
    "        cm_df = pd.DataFrame(cm, index=['true_0', 'true_1'], columns=['pred_0', 'pred_1'])\n",
    "        cm_fig = px.imshow(cm_df, text_auto=True,\n",
    "                           title=f\"Confusión (umbral percentil {percentil} -> prob >= {thresh:.3f})\",\n",
    "                           color_continuous_scale='Blues')\n",
    "        return roc_fig, cm_fig\n",
    "\n",
    "    return px.scatter(title=\"Ejecución analisis_modelado.py primero\"), px.imshow([[0, 0], [0, 0]], title=\"Sin datos\")\n",
    "\n",
    "# --------------------------\n",
    "# Run server\n",
    "# --------------------------\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401e3dc9-d35b-4047-af1f-7e55112cb827",
   "metadata": {},
   "source": [
    "# 9. Informe sobre el  Proyecto – Dashboard de Tsunamis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d5e22-1ea0-4247-b226-210341fea70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "El objetivo principal  del proyecto se baso en el desarrollo de un dashboard interactivo que permitiera explorar y analizar datos de tsunamis, enfocados en el analisis de  la altura máxima de las olas y modelos predictivos de regresión y clasificación.\n",
    "El trabajo combina ciencia de datos (procesamiento, modelado y evaluación) en conjunto con visualización interactiva mediante la librería Dash (Plotly).\n",
    "Para lograr el correcto desarrollo del trabajo se debio realizar una serie de pasos que ayudaron a que la información fuera mas solida y veraz. \n",
    "\n",
    "    ***Carga y limpueza de data***\n",
    "    \n",
    "Se utilizó el dataset Runups.csv, asi mismo, se  eliminaron registros con valores nulos en variables claves como  (MAXIMUM_HEIGHT, DISTANCE_FROM_SOURCE, TRAVEL_TIME_HOURS, PERIOD), Esta decisión asegura que los gráficos y modelos se basen en información consistentes.\n",
    "Es importante tener presente que Los valores faltantes afectaban el rendimiento de los modelos y generaban errores en los gráficos. El filtrado garantizó calidad en el análisis.\n",
    "\n",
    "   ***Exportación de datos***\n",
    "\n",
    "Para la exploración de se incluyeron gráficos exploratorios como: Scatter: magnitud vs altura (o distancia vs altura si no hay magnitud disponible).\n",
    "Histograma: distribución de alturas máximas.\n",
    "Gráfico de barras por país: cantidad de registros en cada región \n",
    "Tabla resumen: primeras filas del datase\n",
    "\n",
    "Estos elementos permitieron identificar patrones y dar contexto sobre la base de datos antes de entrar al modelado.\n",
    "\n",
    "   ***Modelado predictivo***\n",
    "\n",
    "Se emplearon modelos de Regresión Random Forest y Clasificación Random Forest, Se agregaron métricas de rendimiento (MAE, RMSE en regresión; precisión, recall, F1-score en clasificación).\n",
    "asi mismo se mostraron resultados de curva ROC y matriz de confusión para la clasificación.\n",
    "Es importante indicar que el  uso de Random Forest ayudo a equilibrar son precisión y facilidad de implementación. Además, la curva ROC y la matriz de confusión permitio evaluar si el modelo predice adecuadamente eventos extremos.\n",
    "\n",
    "\n",
    "   ***Interactividad (Dash callbacks)***\n",
    "\n",
    "Los Sliders: permitieron filtrar por rango de años y percentil para definir “ola alta”. y el Dropdown + botón reset ayudo a que se pudieran realizar filtros por país, permitiendo reiniciar el filtro.\n",
    "Se puede concluir que la interactividad facilita un análisis exploratorio flexible. El usuario puedra ajustar parámetros y ver cómo cambian las visualizaciones en tiempo real.\n",
    "    \n",
    "    \n",
    "Segun el trabajo realizado se puede decir que la mayoría de olas registradas son de baja altura (< 1 metro). Existiendo relación entre magnitud del evento y altura de la ola, aunque con dispersión.\n",
    "De igual forma Los modelos muestran un rendimiento aceptable, pero un poco limitado para predecir olas altas, esa asi como en el dashboard se diseño del tal manera que  permitiera interactividad \n",
    "para el filtrar y enfocar el análisis según país o periodo.\n",
    "\n",
    "finalmente podemos concluir que se logró integrar exploración de datos, modelos predictivos y narrativa en un mismo dashboard. por otro lado las decisiones de limpieza, uso de Random Forest y filtros interactivos\n",
    "fueron clave para el éxito del proyecto. Asi como se evidencia que el resultado es una herramienta funcional que facilita la comprensión de los datos y del desempeño de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6dd0b3-9ce3-463d-ac1f-7af138a22655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e45da9-afeb-46be-b2be-c9ab3024f7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
